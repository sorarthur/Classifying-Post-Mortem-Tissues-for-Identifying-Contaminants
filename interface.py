# interface.py
# Run: streamlit run interface.py
import cv2
import streamlit as st
import numpy as np
from PIL import Image
import io
import pandas as pd
from streamlit_drawable_canvas import st_canvas
import base64

# Importa as fun√ß√µes dos m√≥dulos de processamento
# Assume que automatic_watershed.py e manual_watershed.py est√£o em uma subpasta 'algoritmos'
# Se estiverem na mesma pasta, remova 'algoritmos.'
try:
    from watershed.automatic_watershed import run_automatic_watershed
    from watershed.manual_watershed import run_manual_watershed
except ModuleNotFoundError:
    st.error("Erro: Certifique-se que os arquivos 'automatic_watershed.py' e 'manual_watershed.py' est√£o na subpasta 'algoritmos' e que a pasta cont√©m um arquivo '__init__.py'.")
    st.stop()


# Importa as fun√ß√µes de valida√ß√£o (do arquivo validation_utils.py na mesma pasta)
try:
    from validation_utils import calculate_metrics, create_overlay, pil_to_cv2, cv2_to_rgb, maybe_downscale
except ModuleNotFoundError:
    st.error("Erro: Arquivo 'validation_utils.py' n√£o encontrado na mesma pasta que 'interface.py'.")
    st.stop()
except ImportError as e:
    st.error(f"Erro ao importar de 'validation_utils.py': {e}. Verifique as fun√ß√µes dentro do arquivo.")
    st.stop()


# --- FUN√á√ÉO DE AJUDA PARA CORRIGIR INCOMPATIBILIDADE ---
# (Necess√°ria se usar Streamlit > 1.17.0, mas mantida por seguran√ßa)
def pil_to_data_url(pil_img: Image.Image) -> str:
    """Converte uma imagem PIL para uma URL de dados Base64 para a web."""
    buffered = io.BytesIO()
    pil_img.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"


st.set_page_config(page_title="An√°lise de Tecidos Post-Mortem", layout="wide")
st.title("üî¨ Classifying Post-mortem Tissues for Identifying Contaminants")

# ======================================================================
# SIDEBAR (Simplificada e Incondicional)
# ======================================================================
st.sidebar.title("‚öôÔ∏è Controles")

# --- Controles de Processamento ---
st.sidebar.subheader("üî¨ Processamento")
processing_method = st.sidebar.selectbox(
    "Escolha o M√©todo",
    # Adiciona modo de depura√ß√£o
    ("Watershed Autom√°tico", "Watershed Manual Interativo", "Debug Coordenadas", "Modelo de IA (em breve)"),
    key="processing_selector"
)
# Mostra o slider de √°rea m√≠nima apenas para os m√©todos Watershed
min_area = 180 # Default value
if "Watershed" in processing_method:
    min_area = st.sidebar.slider("√Årea M√≠nima (px¬≤)", 50, 5000, 180, 10, key="ws_min_area")

st.sidebar.markdown("---")

# --- Controles de Valida√ß√£o ---
st.sidebar.subheader("üìä Valida√ß√£o")
max_side = st.sidebar.slider("Redimensionar Imagem Valida√ß√£o (px)", 0, 3000, 1024, 50, help="0 = n√£o redimensiona.", key="val_max_side")
threshold = st.sidebar.slider("Limiar Binariza√ß√£o Valida√ß√£o", 0, 255, 127, 1, help="Converte predi√ß√µes em grayscale para bin√°rio.", key="val_threshold")


# ======================================================================
# ABAS
# ======================================================================
tab_process, tab_validate, tab_results = st.tabs(["üî¨ Processamento", "üìä Valida√ß√£o", "üñºÔ∏è Resultados Visuais"])

with tab_process:
    st.header("Execu√ß√£o de Algoritmos / Depura√ß√£o") # T√≠tulo atualizado

    uploaded_file = st.file_uploader("Fa√ßa o upload de uma imagem de tecido", type=["png", "jpg", "jpeg", "tif", "tiff", "bmp"], key="process_uploader") # Adicionado Tiff

    if uploaded_file is not None:
        try:
            pil_image = Image.open(uploaded_file).convert("RGB")
            color_image = np.array(pil_image)
            img_width, img_height = pil_image.size
        except Exception as e:
            st.error(f"Erro ao carregar ou converter a imagem: {e}")
            st.stop()


        # --- L√≥gica movida para fora dos ifs espec√≠ficos de m√©todo ---
        CANVAS_HEIGHT = 600 # Altura fixa do canvas
        # Calcula a largura proporcional do canvas para manter o aspect ratio da imagem
        aspect_ratio = img_width / img_height if img_height != 0 else 1
        canvas_width = int(aspect_ratio * CANVAS_HEIGHT)

        # --- NOVO MODO DE DEPURA√á√ÉO ---
        if processing_method == "Debug Coordenadas":
            st.subheader("Modo: Depura√ß√£o de Coordenadas")
            st.info("Clique em pontos identific√°veis na imagem. As coordenadas do Canvas e as calculadas para a imagem original ser√£o exibidas abaixo.")

            canvas_result = st_canvas(
                fill_color="rgba(0, 255, 0, 0.3)", # Cor verde para depura√ß√£o
                stroke_width=3,
                stroke_color="#00FF00",
                background_image=pil_image, # Passa imagem PIL
                update_streamlit=True,      # ATUALIZA A CADA CLIQUE
                height=CANVAS_HEIGHT,
                width=canvas_width,        # Usa largura calculada
                drawing_mode="point",
                key="debug_canvas"
            )

            # Mostra os dados crus do canvas sempre que atualiza
            if canvas_result is not None and canvas_result.json_data is not None and "objects" in canvas_result.json_data and canvas_result.json_data["objects"]:
                st.write("--- Dados do Canvas (Tempo Real) ---")
                st.json(canvas_result.json_data["objects"][-1]) # Mostra apenas o √∫ltimo ponto

                try:
                    markers_df = pd.json_normalize(canvas_result.json_data["objects"])
                    point_markers_df = markers_df[markers_df['type'] == 'circle'].rename(columns={'left': 'x', 'top': 'y'}).tail(1) # Pega s√≥ o √∫ltimo

                    if not point_markers_df.empty:
                        # --- REESCALONAMENTO COM CORRE√á√ÉO APLICADA (DEBUG) ---
                        canvas_height_actual = CANVAS_HEIGHT
                        canvas_width_actual = canvas_width # Usa a largura calculada

                        img_aspect_actual = img_width / img_height if img_height != 0 else 1
                        canvas_aspect_actual = canvas_width_actual / canvas_height_actual if canvas_height_actual != 0 else 1

                        if img_aspect_actual > canvas_aspect_actual:
                            scale = canvas_width_actual / img_width if img_width != 0 else 0
                            offset_x = 0
                            offset_y = (canvas_height_actual - (img_height * scale)) / 2 if scale != 0 else 0
                        else:
                            scale = canvas_height_actual / img_height if img_height != 0 else 0
                            offset_x = (canvas_width_actual - (img_width * scale)) / 2 if scale != 0 else 0
                            offset_y = 0

                        # Define o fator de corre√ß√£o
                        x_correction_pixels = 5

                        # Calcula as coordenadas originais estimadas com corre√ß√£o
                        if scale != 0: # Evita divis√£o por zero
                            point_markers_df['original_x'] = (((point_markers_df['x'] - offset_x) / scale) + x_correction_pixels).astype(int) # Corre√ß√£o aplicada
                            point_markers_df['original_y'] = ((point_markers_df['y'] - offset_y) / scale).astype(int)
                        else:
                            point_markers_df['original_x'] = 0
                            point_markers_df['original_y'] = 0
                        # --- FIM DO REESCALONAMENTO ---

                        st.write("--- Compara√ß√£o de Coordenadas (√öltimo Ponto Corrigido) ---")
                        st.write(f"Scale: {scale:.4f}, OffsetX: {offset_x:.2f}, OffsetY: {offset_y:.2f}, X_Correction: +{x_correction_pixels}")
                        st.dataframe(point_markers_df[['x', 'y', 'original_x', 'original_y']])

                except Exception as e:
                    st.error(f"Erro ao processar coordenadas: {e}")
            else:
                st.write("Aguardando clique...")

        # --- FIM DO NOVO MODO ---

        elif processing_method == "Watershed Autom√°tico":
            st.subheader("Modo: Watershed Autom√°tico")
            # Garante que 'min_area' esteja definido
            current_min_area = min_area if 'min_area' in locals() or 'min_area' in globals() else 180 
            run_auto = st.button("‚ñ∂Ô∏è Executar", type="primary", key="run_auto")
            if run_auto:
                with st.spinner("Processando..."):
                    fig_auto, mask_auto = run_automatic_watershed(color_image, current_min_area)
                    st.pyplot(fig_auto)

        elif processing_method == "Watershed Manual Interativo":
            st.subheader("Modo: Watershed Manual Interativo")
            st.info("Use a ferramenta 'Ponto' para marcar o centro de cada regi√£o. Depois, clique em executar.")

            if 'canvas_data_manual' not in st.session_state:
                st.session_state.canvas_data_manual = None

            canvas_width_manual = canvas_width

            canvas_result = st_canvas(
                fill_color="rgba(255, 165, 0, 0.3)", stroke_width=2, stroke_color="#FF0000",
                background_image=pil_image, # Passa imagem PIL
                update_streamlit=True,      # Mant√©m True para salvar no state
                height=CANVAS_HEIGHT,
                width=canvas_width_manual, # Usa largura calculada
                drawing_mode="point",
                key="canvas"
            )

            # Salva no state
            if canvas_result is not None and canvas_result.json_data is not None:
                st.session_state.canvas_data_manual = canvas_result.json_data

            run_manual = st.button("‚ñ∂Ô∏è Executar com Marcadores", type="primary", key="run_manual") # use_container_width removido

            if run_manual:
                 # L√™ do state e aplica a mesma l√≥gica de reescalonamento da depura√ß√£o
                if 'canvas_data_manual' in st.session_state and st.session_state.canvas_data_manual is not None:
                    canvas_data = st.session_state.canvas_data_manual
                    if "objects" in canvas_data and canvas_data["objects"]:
                        try:
                            markers_df = pd.json_normalize(canvas_data["objects"])
                            point_markers_df = markers_df[markers_df['type'] == 'circle'].rename(columns={'left': 'x', 'top': 'y'}) # Usa 'circle'

                            if not point_markers_df.empty:
                                # --- REESCALONAMENTO COM CORRE√á√ÉO APLICADA (MANUAL) ---
                                canvas_height_actual = CANVAS_HEIGHT
                                canvas_width_actual = canvas_width_manual # Usa a largura do canvas manual

                                img_aspect_actual = img_width / img_height if img_height != 0 else 1
                                canvas_aspect_actual = canvas_width_actual / canvas_height_actual if canvas_height_actual != 0 else 1

                                if img_aspect_actual > canvas_aspect_actual:
                                    scale = canvas_width_actual / img_width if img_width != 0 else 0
                                    offset_x = 0
                                    offset_y = (canvas_height_actual - (img_height * scale)) / 2 if scale != 0 else 0
                                else:
                                    scale = canvas_height_actual / img_height if img_height != 0 else 0
                                    offset_x = (canvas_width_actual - (img_width * scale)) / 2 if scale != 0 else 0
                                    offset_y = 0

                                # Define o fator de corre√ß√£o
                                x_correction_pixels = 5

                                if scale != 0: # Evita divis√£o por zero
                                    point_markers_df['original_x'] = (((point_markers_df['x'] - offset_x) / scale) + x_correction_pixels).astype(int) # Corre√ß√£o aplicada
                                    point_markers_df['original_y'] = ((point_markers_df['y'] - offset_y) / scale).astype(int)
                                else:
                                    point_markers_df['original_x'] = 0
                                    point_markers_df['original_y'] = 0

                                point_markers_df_filtered = point_markers_df[
                                    (point_markers_df['original_x'] >= 0) & (point_markers_df['original_x'] < img_width) &
                                    (point_markers_df['original_y'] >= 0) & (point_markers_df['original_y'] < img_height)
                                ].copy()
                                point_markers_df_filtered = point_markers_df_filtered[['original_x', 'original_y', 'type']].rename(columns={'original_x':'x', 'original_y':'y'})
                                # --- FIM DO REESCALONAMENTO ---

                                if not point_markers_df_filtered.empty:
                                     # Garante que 'min_area' esteja definido
                                     current_min_area = min_area if 'min_area' in locals() or 'min_area' in globals() else 180
                                     with st.spinner("Processando..."):
                                         fig_manual, mask_manual = run_manual_watershed(color_image, current_min_area, point_markers_df_filtered)
                                         st.pyplot(fig_manual)
                                else:
                                    st.warning("Marcadores fora da imagem ap√≥s reescalonamento.")
                            else:
                                st.warning("Nenhum marcador 'c√≠rculo' encontrado.")
                        except Exception as e:
                            st.error(f"Erro ao processar dados do canvas: {e}")
                            st.json(canvas_data if 'canvas_data' in locals() else "Nenhum dado de canvas no estado")
                    else:
                        st.warning("Nenhum marcador desenhado no estado salvo.")
                else:
                     st.warning("Dados do canvas n√£o encontrados no estado da sess√£o.")

        elif processing_method == "Modelo de IA (em breve)":
            st.info("M√≥dulo para carregar e executar modelos de Deep Learning (UNETR, etc.) ser√° implementado aqui.")
            st.image(pil_image)
    else:
        st.info("Aguardando o upload de uma imagem para come√ßar.")


# ======================================================================
# ABA 2: VALIDA√á√ÉO
# ======================================================================
with tab_validate:
    st.header("Valida√ß√£o de M√°scaras de Segmenta√ß√£o")
    st.info("Fa√ßa o upload das imagens originais, das m√°scaras de ground-truth e das predi√ß√µes para calcular as m√©tricas de valida√ß√£o.")

    col1, col2, col3 = st.columns(3)
    with col1:
        original_files = st.file_uploader("1. Imagens Originais (RGB)", accept_multiple_files=True, key="val_orig", type=["png", "jpg", "jpeg", "tif", "tiff", "bmp"])
    with col2:
        gt_files = st.file_uploader("2. M√°scaras Ground-Truth (Bin√°rias)", accept_multiple_files=True, key="val_gt", type=["png", "jpg", "jpeg", "tif", "tiff", "bmp"])
    with col3:
        pred_files = st.file_uploader("3. M√°scaras da Predi√ß√£o", accept_multiple_files=True, key="val_pred", type=["png", "jpg", "jpeg", "tif", "tiff", "bmp"])

    run_val_btn = st.button("‚ñ∂Ô∏è Executar Valida√ß√£o", type="primary", disabled=not (original_files and gt_files and pred_files), key="run_val") # use_container_width removido

    if run_val_btn:
        # Verifica se os par√¢metros da sidebar de valida√ß√£o existem
        current_max_side = max_side if 'max_side' in locals() or 'max_side' in globals() else 1024 # Valor padr√£o
        current_threshold = threshold if 'threshold' in locals() or 'threshold' in globals() else 127 # Valor padr√£o

        original_map = {f.name: f for f in original_files}
        gt_map = {f.name: f for f in gt_files}
        pred_map = {f.name: f for f in pred_files}

        common_names = set(original_map.keys()) & set(gt_map.keys()) & set(pred_map.keys())

        if not common_names:
            st.error("Nenhum arquivo com nome correspondente encontrado entre os tr√™s grupos de upload.")
        else:
            rows, vis_list = [], []
            progress_bar = st.progress(0, text=f"Processando {len(common_names)} imagens...")

            for i, name in enumerate(sorted(list(common_names))):
                try:
                    pil_orig = Image.open(io.BytesIO(original_map[name].read())).convert("RGB")
                    pil_gt = Image.open(io.BytesIO(gt_map[name].read())).convert("L")
                    pil_pred = Image.open(io.BytesIO(pred_map[name].read())).convert("L")

                    bgr, gt_mask, pred_mask_gray = pil_to_cv2(pil_orig), np.array(pil_gt), np.array(pil_pred)

                    bgr = maybe_downscale(bgr, current_max_side) # Usa current_max_side
                    h, w = bgr.shape[:2]
                    gt_mask = cv2.resize(gt_mask, (w, h), interpolation=cv2.INTER_NEAREST)
                    pred_mask_gray = cv2.resize(pred_mask_gray, (w, h), interpolation=cv2.INTER_LINEAR)

                    _, pred_mask = cv2.threshold(pred_mask_gray, current_threshold, 255, cv2.THRESH_BINARY) # Usa current_threshold

                    metrics = calculate_metrics(gt_mask, pred_mask)
                    if metrics:
                        metrics["image"] = name
                        rows.append(metrics)
                    else:
                         st.warning(f"N√£o foi poss√≠vel calcular m√©tricas para {name}. Verifique os tamanhos das m√°scaras.")

                    overlay_img = create_overlay(bgr, gt_mask, pred_mask)
                    vis_list.append({
                        "name": name, "original": cv2_to_rgb(bgr), "ground_truth": gt_mask,
                        "prediction": pred_mask, "overlay": cv2_to_rgb(overlay_img)
                    })
                except Exception as e:
                    st.error(f"Erro ao processar {name}: {e}")

                progress_bar.progress((i + 1) / len(common_names), text=f"Processando {name}...")

            # Salva no estado da sess√£o APENAS ap√≥s o loop terminar com sucesso
            st.session_state.bench_rows = rows
            st.session_state.vis_images = vis_list
            st.success("‚úÖ Valida√ß√£o executada! V√° para a aba **Resultados Visuais**.")


# ======================================================================
# ABA 3: RESULTADOS VISUAIS (da Valida√ß√£o)
# ======================================================================
with tab_results:
    st.header("Resultados da Valida√ß√£o")
    # Verifica se as chaves existem E se as listas n√£o est√£o vazias
    if 'bench_rows' not in st.session_state or not st.session_state.get('bench_rows'):
        st.info("Rode a valida√ß√£o na aba 'üìä Valida√ß√£o' para ver os resultados aqui.")
    else:
        st.subheader("Tabela de M√©tricas")
        try:
            df_results = pd.DataFrame(st.session_state.bench_rows)
            st.dataframe(df_results, use_container_width=True)

            # Exportar CSV
            csv_bytes = df_results.to_csv(index=False).encode("utf-8")
            st.download_button("‚¨áÔ∏è Baixar M√©tricas (CSV)", data=csv_bytes, file_name="validation_metrics.csv", mime="text/csv", key="dl_csv_val")

        except Exception as e:
             st.error(f"Erro ao criar ou exibir DataFrame de m√©tricas: {e}")
             st.write("Dados brutos das m√©tricas:")
             st.json(st.session_state.bench_rows)


        if 'vis_images' in st.session_state and st.session_state.get('vis_images'):
            st.subheader("Resultados Visuais")
            for item in st.session_state.vis_images:
                try:
                    st.markdown(f"#### {item.get('name', 'Nome Desconhecido')}")
                    cols = st.columns(4)
                    cols[0].image(item.get("original"), caption="Original", use_container_width=True)
                    cols[1].image(item.get("ground_truth"), caption="Ground-Truth", use_container_width=True)
                    cols[2].image(item.get("prediction"), caption="Predi√ß√£o Binarizada", use_container_width=True)
                    cols[3].image(item.get("overlay"), caption="Sobreposi√ß√£o (TP:Verde, FP:Vermelho, FN:Azul)", use_container_width=True)
                except Exception as e:
                    st.error(f"Erro ao exibir imagens para {item.get('name', 'Nome Desconhecido')}: {e}")
        else:
             st.warning("Nenhuma imagem de resultado visual encontrada no estado da sess√£o.")