# interface.py
# Run: streamlit run interface.py
import cv2
import streamlit as st
import numpy as np
from PIL import Image
import io
import pandas as pd
from streamlit_drawable_canvas import st_canvas
import base64

# Importa as fun√ß√µes dos m√≥dulos de processamento
from watershed.automatic_watershed import run_automatic_watershed
from watershed.manual_watershed import run_manual_watershed

# Importa as fun√ß√µes de valida√ß√£o
from validation_utils import calculate_metrics, create_overlay, pil_to_cv2, cv2_to_rgb, maybe_downscale

# --- FUN√á√ÉO DE AJUDA PARA CORRIGIR INCOMPATIBILIDADE ---
def pil_to_data_url(pil_img: Image.Image) -> str:
    """Converte uma imagem PIL para uma URL de dados Base64 para a web."""
    buffered = io.BytesIO()
    pil_img.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"


st.set_page_config(page_title="An√°lise de Tecidos Post-Mortem", layout="wide")
st.title("üî¨ Classifying Post-mortem Tissues for Identifying Contaminants")

# ======================================================================
# SIDEBAR (Simplificada e Incondicional)
# ======================================================================
st.sidebar.title("‚öôÔ∏è Controles")

# --- Controles de Processamento (Sempre vis√≠veis) ---
st.sidebar.subheader("üî¨ Processamento")
processing_method = st.sidebar.selectbox(
    "Escolha o M√©todo",
    ("Watershed Autom√°tico", "Watershed Manual Interativo", "Modelo de IA (em breve)"),
    key="processing_selector"
)
if "Watershed" in processing_method:
    min_area = st.sidebar.slider("√Årea M√≠nima (px¬≤)", 50, 5000, 180, 10, key="ws_min_area")

st.sidebar.markdown("---")

# --- Controles de Valida√ß√£o (Sempre vis√≠veis) ---
st.sidebar.subheader("üìä Valida√ß√£o")
max_side = st.sidebar.slider("Redimensionar Imagem (px)", 0, 3000, 1024, 50, help="0 = n√£o redimensiona.", key="val_max_side")
threshold = st.sidebar.slider("Limiar de Binariza√ß√£o", 0, 255, 127, 1, help="Converte predi√ß√µes em grayscale para bin√°rio.", key="val_threshold")


# ======================================================================
# ABAS
# ======================================================================
tab_process, tab_validate, tab_results = st.tabs(["üî¨ Processamento", "üìä Valida√ß√£o", "üñºÔ∏è Resultados Visuais"])


with tab_process:
    st.header("Execu√ß√£o de Algoritmos de Segmenta√ß√£o")
    
    uploaded_file = st.file_uploader("Fa√ßa o upload de uma imagem de tecido", type=["png", "jpg", "jpeg", "tif"], key="process_uploader")

    if uploaded_file is not None:
        pil_image = Image.open(uploaded_file).convert("RGB")
        color_image = np.array(pil_image)

        # Agora l√™ o valor do selectbox diretamente
        if processing_method == "Watershed Autom√°tico":
            st.subheader("Modo: Watershed Autom√°tico")
            run_auto = st.button("‚ñ∂Ô∏è Executar", type="primary", key="run_auto")
            if run_auto:
                with st.spinner("Processando..."):
                    fig_auto, mask_auto = run_automatic_watershed(color_image, min_area)
                    st.pyplot(fig_auto)
        
        elif processing_method == "Watershed Manual Interativo":
            st.subheader("Modo: Watershed Manual Interativo")
            st.info("Use a ferramenta 'Ponto' para marcar o centro de cada regi√£o. Depois, clique em executar.")

            # --- IN√çCIO DAS ALTERA√á√ïES ---

            # 1. Inicializa uma vari√°vel no session_state para guardar os dados do canvas
            if 'canvas_data_manual' not in st.session_state:
                st.session_state.canvas_data_manual = None

            CANVAS_HEIGHT = 400
            img_width, img_height = pil_image.size
            aspect_ratio = img_width / img_height
            new_width = int(aspect_ratio * CANVAS_HEIGHT)
            # N√£o precisamos redimensionar aqui, passamos a imagem original
            # resized_pil_image = pil_image.resize((new_width, CANVAS_HEIGHT))

            canvas_result = st_canvas(
                fill_color="rgba(255, 165, 0, 0.3)",
                stroke_width=2,
                stroke_color="#FF0000",
                background_image=pil_image, # Passa a imagem PIL original
                update_streamlit=True,       # <--- VOLTA PARA TRUE
                height=CANVAS_HEIGHT,
                # width=new_width,
                drawing_mode="point",
                key="canvas" # Mant√©m a key
            )

            # 2. Sempre que o canvas atualizar (update_streamlit=True),
            #    salva os dados JSON na nossa vari√°vel de estado
            if canvas_result is not None and canvas_result.json_data is not None:
                st.session_state.canvas_data_manual = canvas_result.json_data

            # --- FIM DAS ALTERA√á√ïES ---

            # --- In√≠cio da se√ß√£o do bot√£o ---
            # --- In√≠cio da se√ß√£o do bot√£o ---
            # --- In√≠cio da se√ß√£o do bot√£o ---
            run_manual = st.button("‚ñ∂Ô∏è Executar com Marcadores", type="primary", key="run_manual")

            if run_manual:
                # --- DEPURA√á√ÉO FINAL ---
                st.write("--- DEBUG: Checking saved state on button click ---")
                if 'canvas_data_manual' in st.session_state:
                    st.write("`canvas_data_manual` exists in session state:")
                    st.json(st.session_state.canvas_data_manual) # Mostra o que foi salvo
                else:
                    st.write("`canvas_data_manual` NOT FOUND in session state.")
                st.write("--- END DEBUG ---")
                # --- FIM DEPURA√á√ÉO ---

                # L√™ os dados da nossa vari√°vel de estado
                if 'canvas_data_manual' in st.session_state and st.session_state.canvas_data_manual is not None:
                    canvas_data = st.session_state.canvas_data_manual

                    if "objects" in canvas_data and canvas_data["objects"]:
                        try:
                            markers_df = pd.json_normalize(canvas_data["objects"])

                            # Depura√ß√£o anterior (pode remover se quiser)
                            # st.write("--- DEBUG: Raw Markers DataFrame (Before Filtering) ---")
                            # st.dataframe(markers_df)
                            # st.write("--- END DEBUG ---")

                            if 'type' in markers_df.columns:
                                point_markers_df = markers_df[markers_df['type'] == 'circle'].rename(columns={'left': 'x', 'top': 'y'}) # Usa 'circle'
                            else:
                                st.error("Erro: Coluna 'type' n√£o encontrada.")
                                st.json(canvas_data["objects"])
                                point_markers_df = pd.DataFrame()

                            if not point_markers_df.empty:

                                # --- REESCALONAMENTO PRECISO ---
                                img_width, img_height = pil_image.size # Tamanho original
                                canvas_height = CANVAS_HEIGHT
                                # Recalcula a largura do canvas baseada na propor√ß√£o da imagem original
                                canvas_width = int((img_width / img_height) * canvas_height) 

                                # Calcula as propor√ß√µes
                                img_aspect = img_width / img_height
                                canvas_aspect = canvas_width / canvas_height # Propor√ß√£o do espa√ßo onde a imagem √© desenhada

                                # Determina a escala real e os offsets
                                if img_aspect > canvas_aspect:
                                    # Imagem mais larga que o espa√ßo do canvas -> ajustada pela largura
                                    scale = canvas_width / img_width
                                    final_render_height = img_height * scale
                                    offset_x = 0
                                    offset_y = (canvas_height - final_render_height) / 2
                                else:
                                    # Imagem mais alta ou propor√ß√£o igual -> ajustada pela altura
                                    scale = canvas_height / img_height
                                    final_render_width = img_width * scale
                                    offset_x = (canvas_width - final_render_width) / 2
                                    offset_y = 0

                                # --- DEPURA√á√ÉO (Manter para verificar) ---
                                st.write("--- DEBUG: Rescaling V3 ---")
                                st.write(f"Image WxH: {img_width}x{img_height} (Aspect: {img_aspect:.2f})")
                                st.write(f"Canvas WxH (calculated): {canvas_width}x{canvas_height} (Aspect: {canvas_aspect:.2f})")
                                st.write(f"Scale applied: {scale:.4f}")
                                st.write(f"Offsets (X, Y): {offset_x:.2f}, {offset_y:.2f}")
                                st.write("Canvas Coords (Raw):")
                                st.dataframe(point_markers_df[['x', 'y']].head())
                                # --- FIM DEPURA√á√ÉO ---

                                # Aplica a transforma√ß√£o inversa:
                                # 1. Subtrai o offset do canvas
                                # 2. Divide pela escala para obter coords da imagem original
                                point_markers_df['original_x'] = ((point_markers_df['x'] - offset_x) / scale).astype(int)
                                point_markers_df['original_y'] = ((point_markers_df['y'] - offset_y) / scale).astype(int)

                                # --- DEPURA√á√ÉO (Manter para verificar) ---
                                st.write("Rescaled Coords (Original Image):")
                                st.dataframe(point_markers_df[['original_x', 'original_y']].head().rename(columns={'original_x':'x', 'original_y':'y'}))
                                # --- FIM DEPURA√á√ÉO ---

                                # Filtra pontos fora da imagem original
                                point_markers_df_filtered = point_markers_df[
                                    (point_markers_df['original_x'] >= 0) & (point_markers_df['original_x'] < img_width) &
                                    (point_markers_df['original_y'] >= 0) & (point_markers_df['original_y'] < img_height)
                                ].copy()

                                # Renomeia as colunas para o formato esperado por manual_watershed.py ('x', 'y')
                                point_markers_df_filtered = point_markers_df_filtered[['original_x', 'original_y', 'type']].rename(columns={'original_x':'x', 'original_y':'y'})


                                # --- DEPURA√á√ÉO (Manter para verificar) ---
                                st.write(f"Markers remaining after filtering: {len(point_markers_df_filtered)} / {len(point_markers_df)}")
                                st.write("--- END DEBUG ---")
                                # --- FIM DEPURA√á√ÉO ---

                                if not point_markers_df_filtered.empty:
                                    with st.spinner("Processando..."):
                                        # Passa os marcadores filtrados e reescalados corretamente
                                        fig_manual, mask_manual = run_manual_watershed(color_image, min_area, point_markers_df_filtered)
                                        st.pyplot(fig_manual)
                                else:
                                    st.warning("Nenhum marcador v√°lido encontrado dentro dos limites da imagem ap√≥s o reescalonamento.")

                            else:
                                st.warning("Nenhum marcador do tipo 'c√≠rculo' foi encontrado nos dados do canvas.")

                        except Exception as e:
                            st.error(f"Erro ao processar os dados do canvas: {e}")
                            st.write("Dados salvos no session_state:")
                            st.json(st.session_state.canvas_data_manual)

                    else: # A chave 'objects' n√£o existe ou est√° vazia
                        st.warning("Nenhum marcador foi desenhado no canvas.") # <<< A MENSAGEM QUE VOC√ä EST√Å VENDO

                else: # A vari√°vel 'canvas_data_manual' n√£o existe ou √© None
                     st.warning("Nenhum dado de desenho recebido do canvas no estado da sess√£o.")
            # --- Fim da l√≥gica do bot√£o ---

        # ... (resto do c√≥digo) ...
            # --- Fim da l√≥gica do bot√£o ---

        elif processing_method == "Modelo de IA (em breve)":
             # ... (c√≥digo inalterado) ...
            st.info("M√≥dulo para carregar e executar modelos de Deep Learning (UNETR, etc.) ser√° implementado aqui.")
            st.image(pil_image)


with tab_validate:
    st.header("Valida√ß√£o de M√°scaras de Segmenta√ß√£o")
    st.info("Fa√ßa o upload das imagens originais, das m√°scaras de ground-truth e das predi√ß√µes para calcular as m√©tricas de valida√ß√£o.")

    col1, col2, col3 = st.columns(3)
    with col1:
        original_files = st.file_uploader("1. Imagens Originais (RGB)", accept_multiple_files=True, key="val_orig")
    with col2:
        gt_files = st.file_uploader("2. M√°scaras Ground-Truth (Bin√°rias)", accept_multiple_files=True, key="val_gt")
    with col3:
        pred_files = st.file_uploader("3. M√°scaras da Predi√ß√£o", accept_multiple_files=True, key="val_pred")

    run_val_btn = st.button("‚ñ∂Ô∏è Executar Valida√ß√£o", type="primary", disabled=not (original_files and gt_files and pred_files), key="run_val")

    if run_val_btn:
        original_map = {f.name: f for f in original_files}
        gt_map = {f.name: f for f in gt_files}
        pred_map = {f.name: f for f in pred_files}
        
        common_names = set(original_map.keys()) & set(gt_map.keys()) & set(pred_map.keys())
        
        if not common_names:
            st.error("Nenhum arquivo com nome correspondente encontrado entre os tr√™s grupos de upload.")
        else:
            rows, vis_list = [], []
            progress_bar = st.progress(0, text=f"Processando {len(common_names)} imagens...")

            for i, name in enumerate(sorted(list(common_names))):
                pil_orig = Image.open(io.BytesIO(original_map[name].read())).convert("RGB")
                pil_gt = Image.open(io.BytesIO(gt_map[name].read())).convert("L")
                pil_pred = Image.open(io.BytesIO(pred_map[name].read())).convert("L")
                
                bgr, gt_mask, pred_mask_gray = pil_to_cv2(pil_orig), np.array(pil_gt), np.array(pil_pred)
                
                bgr = maybe_downscale(bgr, max_side)
                h, w = bgr.shape[:2]
                gt_mask = cv2.resize(gt_mask, (w, h), interpolation=cv2.INTER_NEAREST)
                pred_mask_gray = cv2.resize(pred_mask_gray, (w, h), interpolation=cv2.INTER_LINEAR)

                _, pred_mask = cv2.threshold(pred_mask_gray, threshold, 255, cv2.THRESH_BINARY)
                
                metrics = calculate_metrics(gt_mask, pred_mask)
                if metrics:
                    metrics["image"] = name
                    rows.append(metrics)
                
                overlay_img = create_overlay(bgr, gt_mask, pred_mask)
                vis_list.append({
                    "name": name, "original": cv2_to_rgb(bgr), "ground_truth": gt_mask,
                    "prediction": pred_mask, "overlay": cv2_to_rgb(overlay_img)
                })
                progress_bar.progress((i + 1) / len(common_names), text=f"Processando {name}...")

            st.session_state.bench_rows = rows
            st.session_state.vis_images = vis_list
            st.success("‚úÖ Valida√ß√£o executada! V√° para a aba **Resultados Visuais**.")


with tab_results:
    st.header("Resultados da Valida√ß√£o")
    if 'bench_rows' not in st.session_state or not st.session_state.bench_rows:
        st.info("Rode a valida√ß√£o na aba 'üìä Valida√ß√£o' para ver os resultados aqui.")
    else:
        st.subheader("Tabela de M√©tricas")
        st.dataframe(pd.DataFrame(st.session_state.bench_rows), use_container_width=True)

        st.subheader("Resultados Visuais")
        for item in st.session_state.vis_images:
            st.markdown(f"#### {item['name']}")
            cols = st.columns(4)
            cols[0].image(item["original"], caption="Original", use_container_width=True)
            cols[1].image(item["ground_truth"], caption="Ground-Truth", use_container_width=True)
            cols[2].image(item["prediction"], caption="Predi√ß√£o Binarizada", use_container_width=True)
            cols[3].image(item["overlay"], caption="Sobreposi√ß√£o (TP:Verde, FP:Vermelho, FN:Azul)", use_container_width=True)

        st.subheader("Exportar")
        csv_bytes = pd.DataFrame(st.session_state.bench_rows).to_csv(index=False).encode("utf-8")
        st.download_button("‚¨áÔ∏è Baixar CSV", data=csv_bytes, file_name="validation_metrics.csv", mime="text/csv")